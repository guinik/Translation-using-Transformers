{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will import from DataandTokenizer, we have everything setup as if it was a non jupyter notebook\n",
    "#explanations can be found of Basic Manipulation with explanation\n",
    "\n",
    "%run DataandTokenizer.ipynb\n",
    "\n",
    "#Now that we have it run we can go ahead and start preparing our transformer \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage of class Embed\n",
    "Embedding has Embedding.tokenize(data) ->(tokenizedspanish(1 per word),tokenizedpt)as dtype= Tensor\n",
    "\n",
    "\n",
    "Embedding has Embedding.detokenize(data) ->(detokenizedspanish,detokenizedpt) as dtype= Tensor\n",
    "\n",
    "Data has to have dimensions (2(spanish,portuguese),datadimension) --> [(esdata),(ptdata)]\n",
    "\n",
    "\n",
    "Be careful with detokenized as it should be decoded again!\n",
    "For now they are only crated for the specific case of spanish and pt.\n",
    "\n",
    "It will include de START AND END ALSO in both \n",
    "\n",
    "## Usage of class Data\n",
    "Data() -> Data.pt ->(Data pt) dimension(words)\n",
    "\n",
    "\n",
    "       -> Data.es ->(Data es) dimension(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testin\n",
    "\n",
    "Datos=Data()\n",
    "Embed=Embedding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`` no dicen , `` '' quiero mejor agua caliente en las duchas . ''\n",
      "[<tf.Tensor: shape=(2, 23), dtype=int64, numpy=\n",
      "array([[   2,   38,   38,  197,  776,   14,   38,   38,    9,    9,  324,\n",
      "         333,  442, 2805,  191,  200,   42, 1070, 2101,   16,    9,    9,\n",
      "           3],\n",
      "       [   2,  282,   16,   10,  281,   11,    3,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0]], dtype=int64)>, <tf.Tensor: shape=(2, 24), dtype=int64, numpy=\n",
      "array([[   2,   39,   39,  162,  117,  658,   28,   39,   39,    9,    9,\n",
      "         264,  373, 1950,  133,   42,  523,  201,  557, 1674,   16,    9,\n",
      "           9,    3],\n",
      "       [   2,  282,   16,   10,  209,   11,    3,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0]], dtype=int64)>]\n",
      "[<tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b\"[START] ` ` no dicen , ` ` ' ' quiero mejor agua caliente en las duchas . ' ' [END]\",\n",
      "       b'[START] gracias . ( aplausos ) [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'],\n",
      "      dtype=object)>, <tf.Tensor: shape=(2,), dtype=string, numpy=\n",
      "array([b\"[START] ` ` eles n\\xc3\\xa3o dizem : ` ` ' ' quero \\xc3\\xa1gua quente nos chuveiros . ' ' [END]\",\n",
      "       b'[START] obrigado . ( aplausos ) [END] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'],\n",
      "      dtype=object)>]\n"
     ]
    }
   ],
   "source": [
    "#TO UNDERSTAND DIMENSIONALITY\n",
    "print(Datos.es[12])\n",
    "test=[]\n",
    "testes=[]\n",
    "testpt=[]\n",
    "testes.append(Datos.es[12])\n",
    "testpt.append(Datos.pt[12])\n",
    "\n",
    "testes.append(Datos.es[13])\n",
    "testpt.append(Datos.pt[13])\n",
    "test.append(testes)\n",
    "test.append(testpt)\n",
    "print(Embed.tokenize(test))\n",
    "print(Embed.detokenize(Embed.tokenize(test)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now following the structure of the transformer we need a positional codificator. We will use the one described in https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can precompute all the positional arguments in a single numpy array \n",
    "\n",
    "def angle(pos,i,dimension):\n",
    "    return pos / np.power(10000, (2 * (i//2)) / np.float32(dimension))\n",
    "   \n",
    "def positional(pos,dimension):\n",
    "    posmatrix=np.arange(pos)[:,np.newaxis]\n",
    "    dimmatrix=np.arange(dimension)[np.newaxis,:]\n",
    "    angles=angle(posmatrix,dimmatrix,dimension)\n",
    "    i=0\n",
    "    for substack in angles:\n",
    "        i=0\n",
    "        for value in substack:\n",
    "            if i%2==0:\n",
    "                value=np.sin(value)#~we apply what is desired\n",
    "            else:\n",
    "                value=np.cos(value)\n",
    "            i+=1\n",
    "    \n",
    "    #this will return a [ [](dimensions) ,... []] for every position we have dimension values think it as an embedding dimension\n",
    "    return angles\n",
    "#And we have or positional embedding fully defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need padding mask and another mask to not let it read ahead.\n",
    "The padding masked just makes 0 if its non padding, meaning its non zero value, and 1 if its 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paddingmask(data):\n",
    "    #data will have dims (batchsize, sequence)\n",
    "    #for attention layers we will include two extra dimensions(batchsize,1,1,sequence)\n",
    "    data = tf.cast(tf.math.equal(data, 0), tf.float32)\n",
    "    #we do math equal in case of true cast will make it a 1.0 otherwise it will be false and cast into 0.0\n",
    "    \n",
    "    return data[:,tf.newaxis,tf.newaxis,:]\n",
    "\n",
    "def lookahead(dimension): #Dimensions has shape (dim,dim)\n",
    "    #what we want is something that has first 0.0 and 1.0 for all values in the first row and then add another 0.0 for each row until \n",
    "    #completed\n",
    "    #we will give dimension of the maximum sequence length ie(1,5) a sequence of five words \n",
    "    #in general we will have a (sequence,sequence) output dimension\n",
    "    res=np.ones(dimension)\n",
    "    for index,value in enumerate(res):\n",
    "        res[index:,index]=0.0\n",
    "        #we set from (x,x) to below as 0\n",
    "        \n",
    "    return tf.convert_to_tensor(res)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put 0, where one would find reasonable to put 1. This is because we multiply by -inf to create a similar result when applying softmax. That is a 0 is going to have much more impact\n",
    "\n",
    "Now we are ready to tackle the attention part of the paper.\n",
    "\n",
    "\n",
    "# Dot product attention\n",
    "The structure and formulas can be found on the paper. We need some set of Queries, Keys and Values that encapsulate the information between relationship of words and the value of a set word in a sentence.\n",
    "\n",
    "\n",
    "A relly important step is that we sum the mask to the result that we are achieving multiplied to a value close to -inf. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dotproductattention(q,k,v,mask):\n",
    "    \n",
    "    \n",
    "    #First we need to matmul q,k transposing k\n",
    "    resmatmul=tf.matmul(q,k,transpose_b=True)\n",
    "    \n",
    "    #then we need the dimension of k d_k \n",
    "    kdim=float(tf.shape(k)[-1])\n",
    "    resmatmul=resmatmul/(tf.math.sqrt(kdim))\n",
    "    \n",
    "    #It may be useful to include the situation where mask is None\n",
    "    if mask is not None:\n",
    "        resmatmul += mask*-1e9\n",
    "    \n",
    "    ressoftmax=tf.nn.softmax(resmatmul,axis=-1) # we need to do softmax on the last dimension\n",
    "    return tf.matmul(ressoftmax,v), ressoftmax\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_k = tf.constant([[10, 0, 0],\n",
    "                      [0, 10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[1, 0],\n",
    "                      [10, 0],\n",
    "                      [100, 5],\n",
    "                      [1000, 6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[10, 0, 0]], dtype=tf.float32)  # (1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[1.000000e+00, 9.276602e-25]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 4), dtype=float32, numpy=\n",
       " array([[1.0000000e+00, 8.4332744e-26, 8.4332744e-26, 8.4332744e-26]],\n",
       "       dtype=float32)>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotproductattention(temp_q,temp_k,temp_v,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that remains now is to create the multi head attention. The powerful idea of multi-head is the usage of parallel computation so what the papers does is project in a number of dotproductattention layers, and then concatanate the result\n",
    "\n",
    "\n",
    "Also each queries,keys and values will need their respective weights as described in the paper. That is a keras Dense model(lineal). We will call the dimension of these weights the modeldim. \n",
    "\n",
    "\n",
    "\n",
    "We need to create a class that is a Layer of keras that is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,modeldim,layersnum): \n",
    "        # we need to inherit all of the keras information of th super\n",
    "        super().__init__()\n",
    "        #now we can start working\n",
    "        \n",
    "        #WEIGHTS FOR Q,K,V\n",
    "        self.wq=tf.keras.layers.Dense(modeldim)\n",
    "        self.wk=tf.keras.layers.Dense(modeldim)\n",
    "        self.wv=tf.keras.layers.Dense(modeldim)\n",
    "                          \n",
    "            \n",
    "        #WEIGHTS FO AFTER CONCATENTION\n",
    "        self.dense=tf.keras.layers.Dense(modeldim)\n",
    "        \n",
    "        #extra information\n",
    "        \n",
    "        self.modeldim=modeldim\n",
    "        self.layersnum=layersnum\n",
    "        assert d_model % self.num_heads == 0\n",
    "        self.depth=d_model//self.num_heads\n",
    "        \n",
    "        \n",
    "    #WE NEED TO SPLIT INTO modeldim /layresnum\n",
    "    \n",
    "    #All this part is heavily optimized thanks to the tensorflow tutorial for transformers\n",
    "    #The main idea is to split the last dimension into (number of layers, model dimension)\n",
    "    def split_heads(self, x, batch_size):\n",
    "        #Split the last dimension into (num_heads, depth).\n",
    "        #Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        #\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mul=MultiAttention(10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Layer at 0x2106e5d50a0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mul.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
